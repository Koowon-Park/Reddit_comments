---
title: "LLM Integration"
format:
  html:
    toc: true
    number-sections: true
    embed-resources: true
    link-styles: true
---

# LLM Integration
Given the very dense nature of the graphs produced on Neo4J, we decided to integrate an LLM to help us analyze its output. Indeed, our Reddit comments dataset contains more than 30'000 observations, linked between each other through various metrics, such as sentiment, score, theme, etc.

For the LLM integration, we decided to use OpenAI's API because of computational limitations on local LLMs. The model chosen is 4o-mini, to ensure a smooth, reliable, yet cheap process. The workflow for this API being standardized in Python, we use a virtual environment through the reticulate package to run Python code in RStudio. We then activate the script/virtual environment through the console. 

This process being burdensome, we present on this page the outputs generated by OpenAI's 4o-mini for 3 given queries made on Neo4J, to show its efficacy and flexibility. 

```{r, message=FALSE, warning=FALSE}
library(reticulate)
library(here)
venv_path <- here("venv")
if (!dir.exists(venv_path)) {
  virtualenv_create(venv_path)
  virtualenv_install(venv_path, packages = c("pandas", "transformers", "neo4j", "openai"))
}

virtualenv_install(venv_path, packages = c("openai"))
use_virtualenv(venv_path, required = TRUE)


#use_python("C:\Users\troen\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Python 3.10")
py_config()
```

## NEO4J & OpenAI

The following code uses the OpenAI and Neo4j packages in python to access the 4o-mini API and the neo4j data respectively. The data fetched from Neo4J is then formatted dynamically based on the query. This dynamic format is then used to adapt the prompt based on the query. Finally, the data and the prompt are fed to the LLM API to get an analysis.

### First example

```{python}
#install neo4j
from neo4j import GraphDatabase

from openai import OpenAI

uri = "bolt://localhost:7687"

#connect to the database
driver = GraphDatabase.driver(uri, auth=("neo4j", "12345678"))

def fetch_data(query):
    with driver.session() as session:
        result = session.run(query)
        return [record for record in result]

# Query example
query = """MATCH (n)-[r:THEME_AUTHORS]-(a1:Author) 
with count(n) as deg1,a1 order by deg1 desc limit 10
MATCH (a1)-[:THEME_AUTHORS]-(n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, count(n) as common ,deg1,  a2 order by common desc 
MATCH (n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, a2, common, deg1, count(n) as deg2 
with a1,a2, common, deg1, deg2, 100*common/(deg1+deg2-common) as simi order by simi desc
with a1 , collect(a2)[..5] as author_list
unwind author_list as a2
MATCH (a1)--(t)--(a2)
return a1,t,a2
"""

data = fetch_data(query)

# Extract data in a usable format
def format_records(records):
    formatted_records = []
    for record in records:
        formatted_record = {}
        for key, value in record.items():
            formatted_record[key] = value
        formatted_records.append(formatted_record)
    return formatted_records

comments = format_records(data)

# Display formatted results in a readable structure
def display_formatted_results(records):
    formatted_output = "### Formatted Neo4j Output\n\n"
    for record in records:
        formatted_output += "- Record:\n"
        for key, value in record.items():
            formatted_output += f"  - {key}: {value}\n"
        formatted_output += "\n"
    return formatted_output

formatted_comments = display_formatted_results(comments)


neo4j_output = comments

client= OpenAI(api_key="API")

# Prepare the prompt
prompt = (
    "You are an assistant trained to analyze Neo4j database query outputs. "
    "Given the output of a query, analyze its content and provide insights on the relationships (if you see any bots, also provide interpretation) and possible patterns observed."
)

completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": f"{prompt}\nQuery Output:\n{formatted_comments}"}
    ]
)

print(completion.choices[0].message.content)
```

### Second example
```{python}
uri = "bolt://localhost:7687"

#connect to the database
driver = GraphDatabase.driver(uri, auth=("neo4j", "12345678"))

def fetch_data(query):
    with driver.session() as session:
        result = session.run(query)
        return [record for record in result]

# Query example
query = """MATCH (n)-[r:THEME_AUTHORS]-(a1:Author) 
with count(n) as deg1,a1 order by deg1 desc limit 100
MATCH (a1)-[:THEME_AUTHORS]-(n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, count(n) as common ,deg1,  a2 order by common desc 
MATCH (n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, a2, common, deg1, count(n) as deg2 
with a1,a2, common, deg1, deg2, 100*common/(deg1+deg2-common) as simi order by simi desc
with a1 , collect(a2)[..5] as author_list
unwind author_list as a2
return a1.id,a2.id
"""
data = fetch_data(query)

# Extract data in a usable format
def format_records(records):
    formatted_records = []
    for record in records:
        formatted_record = {}
        for key, value in record.items():
            formatted_record[key] = value
        formatted_records.append(formatted_record)
    return formatted_records

comments = format_records(data)

# Display formatted results in a readable structure
def display_formatted_results(records):
    formatted_output = "### Formatted Neo4j Output\n\n"
    for record in records:
        formatted_output += "- Record:\n"
        for key, value in record.items():
            formatted_output += f"  - {key}: {value}\n"
        formatted_output += "\n"
    return formatted_output

formatted_comments = display_formatted_results(comments)


neo4j_output = comments

client= OpenAI(api_key="API")

# Prepare the prompt
prompt = (
    "You are an assistant trained to analyze Neo4j database query outputs. "
    "Given the output of a query, analyze its content and provide insights on the relationships and possible patterns observed."
)

completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": f"{prompt}\nQuery Output:\n{formatted_comments}"}
    ]
)

print(completion.choices[0].message.content)
```


### Third example
```{python}

uri = "bolt://localhost:7687"

#connect to the database
driver = GraphDatabase.driver(uri, auth=("neo4j", "12345678"))

def fetch_data(query):
    with driver.session() as session:
        result = session.run(query)
        return [record for record in result]

# Query example
query = """MATCH (n)-[r:THEME_AUTHORS]-(a1:Author) 
with count(n) as deg1,a1 order by deg1 desc limit 10
MATCH (a1)-[:THEME_AUTHORS]-(n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, count(n) as common ,deg1,  a2 order by common desc 
MATCH (n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, a2, common, deg1, count(n) as deg2 
with a1,a2, common, deg1, deg2, 100*common/(deg1+deg2-common) as simi order by simi desc
return a1 , collect(a2)[..3]
"""


data = fetch_data(query)

# Extract data in a usable format
def format_records(records):
    formatted_records = []
    for record in records:
        formatted_record = {}
        for key, value in record.items():
            formatted_record[key] = value
        formatted_records.append(formatted_record)
    return formatted_records

comments = format_records(data)

# Display formatted results in a readable structure
def display_formatted_results(records):
    formatted_output = "### Formatted Neo4j Output\n\n"
    for record in records:
        formatted_output += "- Record:\n"
        for key, value in record.items():
            formatted_output += f"  - {key}: {value}\n"
        formatted_output += "\n"
    return formatted_output

formatted_comments = display_formatted_results(comments)


neo4j_output = comments

client= OpenAI(api_key="API")

# Prepare the prompt
prompt = (
    "You are an assistant trained to analyze Neo4j database query outputs. "
    "Given the output of a query, analyze its content and provide insights on the relationships and possible patterns observed."
)

completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": f"{prompt}\nQuery Output:\n{formatted_comments}"}
    ]
)

print(completion.choices[0].message.content)
```

