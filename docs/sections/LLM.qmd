# LLM Integration

Given the very dense nature of the graphs produced on Neo4J, we decided to integrate an LLM to help us analyze its output. Indeed, our Reddit comments dataset contains more than 30'000 observations, linked between each other through various metrics, such as sentiment, score, theme, etc.

For the LLM integration, we decided to use OpenAI's API because of computational limitations on local LLMs. The model chosen is 4o-mini, to ensure a smooth, reliable, yet cheap process. The workflow for this API being standardized in Python, we use a virtual environment through the reticulate package to run Python code in RStudio. We then activate the script/virtual environment through the console.

This process being burdensome, we present on this page the outputs generated by OpenAI's 4o-mini for 3 given queries made on Neo4J, to show its efficacy and flexibility.

```{r, message=FALSE, warning=FALSE, eval=FALSE,  }
#| code-fold: false
library(reticulate)
library(here)
venv_path <- here("venv")
if (!dir.exists(venv_path)) {
  virtualenv_create(venv_path)
  virtualenv_install(venv_path, packages = c("pandas", "transformers", "neo4j", "openai"))
}

virtualenv_install(venv_path, packages = c("openai"))
use_virtualenv(venv_path, required = TRUE)


#use_python("C:\Users\troen\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Python 3.10")
py_config()
```

## NEO4J & OpenAI

The following code uses the OpenAI and Neo4j packages in python to access the 4o-mini API and the neo4j data respectively. The data fetched from Neo4J is then formatted dynamically based on the query. This dynamic format is then used to adapt the prompt based on the query. Finally, the data and the prompt are fed to the LLM API to get an analysis.

Below are three examples of the LLM integration. The text in each examples is the resulting ChatGPT 4o-mini output, pasted as text.

### First example

```{python, eval=FALSE}
#| code-fold: false
#install neo4j
from neo4j import GraphDatabase

from openai import OpenAI

uri = "bolt://localhost:7687"

#connect to the database
driver = GraphDatabase.driver(uri, auth=("neo4j", "12345678"))

def fetch_data(query):
    with driver.session() as session:
        result = session.run(query)
        return [record for record in result]

# Query example
query = """MATCH (n)-[r:THEME_AUTHORS]-(a1:Author) 
with count(n) as deg1,a1 order by deg1 desc limit 10
MATCH (a1)-[:THEME_AUTHORS]-(n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, count(n) as common ,deg1,  a2 order by common desc 
MATCH (n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, a2, common, deg1, count(n) as deg2 
with a1,a2, common, deg1, deg2, 100*common/(deg1+deg2-common) as simi order by simi desc
with a1 , collect(a2)[..5] as author_list
unwind author_list as a2
MATCH (a1)--(t)--(a2)
return a1,t,a2
"""

data = fetch_data(query)

# Extract data in a usable format
def format_records(records):
    formatted_records = []
    for record in records:
        formatted_record = {}
        for key, value in record.items():
            formatted_record[key] = value
        formatted_records.append(formatted_record)
    return formatted_records

comments = format_records(data)

# Display formatted results in a readable structure
def display_formatted_results(records):
    formatted_output = "### Formatted Neo4j Output\n\n"
    for record in records:
        formatted_output += "- Record:\n"
        for key, value in record.items():
            formatted_output += f"  - {key}: {value}\n"
        formatted_output += "\n"
    return formatted_output

formatted_comments = display_formatted_results(comments)


neo4j_output = comments

client= OpenAI(api_key="API")

# Prepare the prompt
prompt = (
    "You are an assistant trained to analyze Neo4j database query outputs. "
    "Given the output of a query, analyze its content and provide insights on the relationships (if you see any bots, also provide interpretation) and possible patterns observed."
)

completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": f"{prompt}\nQuery Output:\n{formatted_comments}"}
    ]
)

print(completion.choices[0].message.content)
```

Here below is ChatGPT's breakdown of the contents and potential insights for the first example:

Key Nodes and Relationships:

1.  **Author Nodes:**
    -   Multiple authors are referenced, including `AutoModerator`, `autowikibot`, `smilesbot`, `TweetPoster`, `drocks27`, `expert02`, among others.
    -   These authors demonstrate different behaviors or contributions associated with various themes.
2.  **Theme Nodes:**
    -   Themes are represented as nodes with varied IDs.
    -   Each author is associated with multiple themes, indicating the likelihood of active participation across diverse topics.
3.  **Relationships:**
    -   Each record represents a connection between an author (`a1`), a theme (`t`), and another author (`a2`), implying collaborative or contributive actions.
    -   The repeated presence of certain authors like `TweetPoster` and `smilesbot` suggests they play a significant role across various themes.
    -   The pairs of authors in `a1` and `a2` show interactions that could convey collaboration, rivalry, or commentary on shared themes.

Observed Patterns:

1.  **Active Collaboration:**
    -   Authors frequently appear multiple times with diverse themes, suggesting high collaboration or overlapping interest areas.
    -   For instance, `smilesbot` appears in several records, partnered with various authors, pointing to a network of collaboration around similar themes.
2.  **Presence of Bots:**
    -   Both `autowikibot` and `smilesbot` are bots, performing automated functions â€” possibly fact-checking or generating content.
    -   Their participation in many interactions indicates their integration into the thematic discussions and content generation.
3.  **Dynamic Interactions:**
    -   There are authors such as `drocks27` and `expert02` also appearing frequently, indicating they may be influential contributors or moderators who often engage in conversations across themes.
    -   Fluctuations in author pairings (`a1` with `a2`) suggest differing degrees of engagement across themes, with potential shifts in themes provoking diverse author participation.
4.  **Thematic Diversity:**
    -   Themes vary considerably (ID ranging from 1 to 20), indicating a rich multilingual landscape potentially encompassing numerous sub-genres or specializations.
    -   The changing authors linked with specific themes may imply the themes evolve over time, attracting various contributors as community or topic interests shift.

Insights and Interpretation:

-   **Engagement Strategy:**
    -   Authors like `AutoModerator` may effectively moderate or incentivize interactions among contributors.
    -   Understanding how themes guide author interactions can help in devising strategies for community engagement or content curation through bots.
-   **Network Analysis:**
    -   Given the interlinked nature of authors and themes, carrying out network analysis could unveil pivotal authors or key topics driving community discussions.
    -   Identifying central nodes (frequently engaged authors) may assist in targeting outreach or understanding influence dynamics.
-   **Behavioral Trends:**
    -   Monitoring the behavior of bot users versus human contributors can yield insights into content automation effects and potentially identify areas for enhancing user experience.

Conclusion:

The data from the Neo4j query highlights a complex interplay of authors and themes, illustrating a vibrant community atmosphere marked by collaboration, thematic diversity, and automation. Further analysis could delve into temporal trends or sentiment analysis to refine understanding of community dynamics.

### Second example

```{python, eval=FALSE}
#| code-fold: true
uri = "bolt://localhost:7687"

#connect to the database
driver = GraphDatabase.driver(uri, auth=("neo4j", "12345678"))

def fetch_data(query):
    with driver.session() as session:
        result = session.run(query)
        return [record for record in result]

# Query example
query = """MATCH (n)-[r:THEME_AUTHORS]-(a1:Author) 
with count(n) as deg1,a1 order by deg1 desc limit 100
MATCH (a1)-[:THEME_AUTHORS]-(n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, count(n) as common ,deg1,  a2 order by common desc 
MATCH (n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, a2, common, deg1, count(n) as deg2 
with a1,a2, common, deg1, deg2, 100*common/(deg1+deg2-common) as simi order by simi desc
with a1 , collect(a2)[..5] as author_list
unwind author_list as a2
return a1.id,a2.id
"""
data = fetch_data(query)

# Extract data in a usable format
def format_records(records):
    formatted_records = []
    for record in records:
        formatted_record = {}
        for key, value in record.items():
            formatted_record[key] = value
        formatted_records.append(formatted_record)
    return formatted_records

comments = format_records(data)

# Display formatted results in a readable structure
def display_formatted_results(records):
    formatted_output = "### Formatted Neo4j Output\n\n"
    for record in records:
        formatted_output += "- Record:\n"
        for key, value in record.items():
            formatted_output += f"  - {key}: {value}\n"
        formatted_output += "\n"
    return formatted_output

formatted_comments = display_formatted_results(comments)


neo4j_output = comments

client= OpenAI(api_key="API")

# Prepare the prompt
prompt = (
    "You are an assistant trained to analyze Neo4j database query outputs. "
    "Given the output of a query, analyze its content and provide insights on the relationships and possible patterns observed."
)

completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": f"{prompt}\nQuery Output:\n{formatted_comments}"}
    ]
)

print(completion.choices[0].message.content)
```

The second example asks 4o-mini to give insights on this query:

```{python, eval=FALSE}
#| code-fold: true
query = """MATCH (n)-[r:THEME_AUTHORS]-(a1:Author) 
with count(n) as deg1,a1 order by deg1 desc limit 100
MATCH (a1)-[:THEME_AUTHORS]-(n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, count(n) as common ,deg1,  a2 order by common desc 
MATCH (n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, a2, common, deg1, count(n) as deg2 
with a1,a2, common, deg1, deg2, 100*common/(deg1+deg2-common) as simi order by simi desc
with a1 , collect(a2)[..5] as author_list
unwind author_list as a2
return a1.id,a2.id
"""
```

Here below is ChatGPT's breakdown of the contents and potential insights for the second example:

The output you provided from the Neo4j database query represents records of relationships between various entities identified by their IDs. Each record consists of a pair of IDs (`a1.id` and `a2.id`), indicating a direct relationship between the two entities. Here are some insights and observations based on the data:

Key Observations:

1.  **Main Entities**:
    -   Certain entities appear repeatedly in the dataset, indicating they're likely central nodes in this network. For instance, `Explore_Uranus`, `Netprincess`, `knightstorm`, `catherder9000`, and `gangli0n` are active participants with multiple connections.
2.  **Bimodal Relationships**:
    -   The dataset contains many mutual connections. For example, the relationships involving `catherder9000` and `knightstorm` suggest that these two entities share a close interaction, as they appear as both `a1` and `a2` in various records.
3.  **Diversity and Clusters**:
    -   Entities like `Explore_Uranus`, `Netprincess`, and `Malos_Kain` connect to a diverse array of other entities, indicating they might be part of larger clusters or communities within the network. Conversely, entities like `adudeguyman` or `Buffalo__Buffalo` seem to have more confined networks.
4.  **Directional Influence**:
    -   From names such as `AutoModerator`, `smilesbot`, `totes_meta_bot`, and others, it is evident that there are automated entities or bots interacting with users. These relationships might indicate a moderated environment that caters to user interactions.
5.  **Patterns in Naming**:
    -   The IDs suggest a variety of user types and possible thematic areas of interest. Some names indicate a humorous or light-hearted approach, while others might imply more serious or specific themes.
6.  **Connectedness**:
    -   Analysis reveals connections like `Dunkelz` to `Dorkamundo`, indicating the cross-linking between different user groups or communities. The presence of overlapping members in communities can be inferred from shared edges.

Patterns and Possible Insights:

1.  **Network Density**:
    -   When certain nodes (like `Explore_Uranus` or `catherder9000`) have many connections, they form hubs in the network. These hubs likely play crucial roles in facilitating interactions across the entire network.
2.  **Community Detection**:
    -   Utilizing algorithms to assess community structure may reveal clusters of highly interconnected users. Communities can be visualized as subgraphs that are denser than connections outside them.
3.  **Importance of Intermediary Nodes**:
    -   Certain entities that act as bridges between groups can be identified. For example, if `Explore_Uranus` connects to both `Netprincess` and `k8reds`, it acts as a critical node linking different participants or clusters.
4.  **Centrality Measures**:
    -   Various centrality metrics (like degree centrality, closeness centrality, and betweenness centrality) can be computed to quantify the influence of particular nodes within the network. This will help in understanding the impact each user has on facilitating communication.
5.  **Temporal Dynamics**:
    -   If time data were integrated into the relationships, you could analyze how interaction patterns evolve over time, perhaps revealing trends or shifts in community interests.

Next Steps:

-   To derive further insights, visualizing the network using graph visualization tools could help identify clusters and pathways.
-   Additionally, examining the metadata associated with each user could provide context to interpret the relationships more meaningfully.
-   Analyzing the frequency and type of interactions may provide additional layers of insight into user engagement and community dynamics.

### Third example

```{python, eval=FALSE}
#| code-fold: true
uri = "bolt://localhost:7687"

#connect to the database
driver = GraphDatabase.driver(uri, auth=("neo4j", "12345678"))

def fetch_data(query):
    with driver.session() as session:
        result = session.run(query)
        return [record for record in result]

# Query example
query = """MATCH (n)-[r:THEME_AUTHORS]-(a1:Author) 
with count(n) as deg1,a1 order by deg1 desc limit 10
MATCH (a1)-[:THEME_AUTHORS]-(n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, count(n) as common ,deg1,  a2 order by common desc 
MATCH (n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, a2, common, deg1, count(n) as deg2 
with a1,a2, common, deg1, deg2, 100*common/(deg1+deg2-common) as simi order by simi desc
return a1 , collect(a2)[..3]
"""


data = fetch_data(query)

# Extract data in a usable format
def format_records(records):
    formatted_records = []
    for record in records:
        formatted_record = {}
        for key, value in record.items():
            formatted_record[key] = value
        formatted_records.append(formatted_record)
    return formatted_records

comments = format_records(data)

# Display formatted results in a readable structure
def display_formatted_results(records):
    formatted_output = "### Formatted Neo4j Output\n\n"
    for record in records:
        formatted_output += "- Record:\n"
        for key, value in record.items():
            formatted_output += f"  - {key}: {value}\n"
        formatted_output += "\n"
    return formatted_output

formatted_comments = display_formatted_results(comments)


neo4j_output = comments

client= OpenAI(api_key="API")

# Prepare the prompt
prompt = (
    "You are an assistant trained to analyze Neo4j database query outputs. "
    "Given the output of a query, analyze its content and provide insights on the relationships and possible patterns observed."
)

completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": f"{prompt}\nQuery Output:\n{formatted_comments}"}
    ]
)

print(completion.choices[0].message.content)
```

The third example asks 4o-mini to give insights on this query:

```{python, eval=FALSE}
#| code-fold: true
query = """MATCH (n)-[r:THEME_AUTHORS]-(a1:Author) 
with count(n) as deg1,a1 order by deg1 desc limit 10
MATCH (a1)-[:THEME_AUTHORS]-(n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, count(n) as common ,deg1,  a2 order by common desc 
MATCH (n)-[r:THEME_AUTHORS]-(a2:Author) 
with a1, a2, common, deg1, count(n) as deg2 
with a1,a2, common, deg1, deg2, 100*common/(deg1+deg2-common) as simi order by simi desc
return a1 , collect(a2)[..3]
"""
```

Here below is ChatGPT's breakdown of the contents and potential insights:

The query output provides a collection of nodes that represent authors, along with their relationships to other authors as determined by the collected `a2` values. Each record consists of an author identified by their `id` and a list of up to three related authors.

Let's analyze the records to extract insights on the relationships and potential patterns:

1.  **Core Author Relationships**:
    -   Each author has connections to a few other authors, suggesting a collaborative or interconnected environment among the authors. This may imply shared topics, interests, or collaborative projects.
2.  **High Connectivity**:
    -   The author `AutoModerator` appears in multiple relationships, suggesting that it may play a central role within this network. Multiple authors reference `AutoModerator`, including `totes_meta_bot`, `autowikibot`, and `TweetPoster`. This could indicate that `AutoModerator` is a significant contributor, possibly acting as a curator or mediator within the group.
3.  **Frequent Appearances**:
    -   Several other authors also appear more than once across different relationships, such as:
        -   `TweetPoster` (seen with `expert02`, `AutoModerator`, and `totes_meta_bot`)
        -   `totes_meta_bot` (connected to `AutoModerator`, `TweetPoster`, and `timewaitsforsome`)
        -   `smilesbot` (connected to `AutoModerator`, `autowikibot`, and `Voduar`)
    -   This recurring pattern suggests that there may be a smaller group of authors who are highly active and interlinked, indicating potential collaboration or influencer dynamics.
4.  **Diverse Interconnections**:
    -   The records show a variety of authors with distinct IDs. Authors like `drocks27`, `knopper91`, and `son_bakazaru` are part of a cluster that does not significantly overlap with others. This can suggest specialization in different areas or topics, thus displaying a wider overall network.
5.  **Potential Clustering Effect**:
    -   The interconnectedness of authors can lead to the formation of clusters or communities within this dataset. For instance, authors like `expert02`, `TweetPoster`, and others form a small cluster. This potential clustering can be useful for identifying groups of authors who may share common interests or collaborate closely.
6.  **Disconnects and Unique Nodes**:
    -   Some authors appear only once in direct relationships, such as `itonlygetsworse` and `Voduar`. This could imply they either operate independently in certain contexts or have not yet formed relationships with the larger network, providing opportunities for networking.

Overall, this dataset presents a snapshot of a potentially collaborative environment among authors, with some prominent figures standing out as pivotal points of connection. Understanding these relationships can help facilitate discussions or initiatives that enhance collaboration and knowledge sharing among authors. Further analysis could involve clustering techniques to visualize and explore these relationships in greater depth.
